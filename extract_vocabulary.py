# -*- coding: utf-8 -*-
"""extract_vocabulary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FsF85LwVyH9FZBw5Ssj_jhAkaxVAJGup

# Imports
"""

!pip install datasets
import pandas as pd
import os
from typing import List
import datasets

"""# Read dataset"""

dataset = datasets.load_dataset("LanguageShades/BiasShades")

print(dataset)

"""# Check format

## Checking the format of biased sentences and sentence templates
Check if:

    - starts with a capital letter
    - ends with a period (or ?, !)
    (for languages where applicable)
"""

# Set language to check
lang = "English"
templates_lang_col = f"{lang}: Templates"
biased_sentence_lang_col = f"{lang}: Biased Sentences"

cols = df_target_tab.columns
df_target_tab = df_target_tab.rename(columns={c: c.strip() for c in cols})
index_col = "Index" if "Index" in df_target_tab.columns else df_target_tab.columns[0]
indices = [str(x) for x in df_target_tab[index_col]]

# TODO: Adapt for other languages
start_symbols = (["¿", "¡"] if lang == "Spanish" else [],)
end_symbols = [".", "!", "?"]


def check_start_end_symbols(column_name: str):
    ret = []
    for index, biased_sentence in zip(
        df_target_tab[index_col], df_target_tab[column_name]
    ):
        biased_sentence = str(biased_sentence).strip()
        if biased_sentence != "nan" and (
            (
                biased_sentence[0] not in start_symbols
                and biased_sentence[0] != biased_sentence[0].upper()
            )
            or (biased_sentence[-1] not in end_symbols)
        ):
            ret.append([index, biased_sentence])
    return ret


biased_sentences2review = check_start_end_symbols(biased_sentence_lang_col)
templates2review = check_start_end_symbols(templates_lang_col)

print("biased_sentences2review:")
for x in biased_sentences2review:
    print(x)

print("templates2review:")
for x in templates2review:
    print(x)



"""
# Align templates with sentences"""

"""
A very simple alignment of template/biased_sentence pairs making certain assumptions about the
aligned strings, may need to be adapted for specific languages.
Used to explore our way of using placeholders in order to standardize them.
May need to be changed to a different method (regex?) for certain languages, especially
when the set of slot types (strings for regex) has been defined.
"""

lang = "English"
templates_lang_col = f"{lang}: Templates"
biased_sentence_lang_col = f"{lang}: Biased Sentences"
# common words that may occur in both the template and the sentence and hinder the simple alignment algorithm
words2remove = {"French": ["de", "des", "les"]}  # More may be needed here


def clean(word: str):
    chars2remove = [
        ".",
        ",",
        "dall'",
        "'s",
        "d'",
        "'",
        "”",
        "“",
        '"',
        "!",
        "?",
        "’s",
        "’",
    ]
    for char in chars2remove:
        word = word.replace(char, "")
    return word


upper_case_not_placeholders = ["AIDS", "SIDA", "LKW", "RPA"]


def is_placeholder(word: str):
    if (
        word.upper() == word
        and len(word) > 2
        and word not in upper_case_not_placeholders
    ):
        return True
    else:
        return False


def align_template_with_sentence(
    template_words: List[str], biased_sentence_words: List[str]
):
    # placeholders = [x for x in template_words if is_placeholder(x)]
    placeholders = []
    last_placeholder_pos = -2
    # merge adjacent placeholders as they are impossible to resolve automatically
    for i, x in enumerate(template_words):
        if is_placeholder(x):
            if last_placeholder_pos == i - 1:
                placeholders[-1] = placeholders[-1] + " " + x
            else:
                placeholders.append(x)
            last_placeholder_pos = i

    aux = (
        ["#"]
        + [x if x in template_words else " " for x in biased_sentence_words]
        + ["#"]
    )
    start, end = -1, -1
    words_aligned = []
    for i in range(len(aux)):
        if aux[i] == " " and aux[i - 1] != " ":
            start = i - 1
        if aux[i] == " " and aux[i + 1] != " ":
            end = i - 1
        if (
            start >= 0
            and end >= 0
            and start < len(biased_sentence_words)
            and start < len(biased_sentence_words)
        ):
            words_aligned.append(biased_sentence_words[start : end + 1])
            start, end = -1, -1

    return placeholders, words_aligned


if "Index" not in df_target_tab.columns:
    indices = [str(x) for x in df_target_tab[df_target_tab.columns[0]]]
else:
    indices = [str(x) for x in df_target_tab["Index"]]
templates = [str(x) for x in df_target_tab[templates_lang_col]]
biased_sentences = [str(x) for x in df_target_tab[biased_sentence_lang_col]]

"""
placeholders_all = set()
for template in templates:
    aux = [clean(x.strip()) for x in template.split(" ") if is_placeholder(x.strip())]
    placeholders_all.update(set(aux))
print(sorted(placeholders_all))
"""

not_aligned = []
alignement_by_placeholder = {}
alignement_by_word = {}
for index, template, biased_sentence in zip(indices, templates, biased_sentences):
    if template and template != "nan" and biased_sentence and biased_sentence != "nan":
        template_source, biased_sentence_source = template, biased_sentence
        template = template.replace("\xa0", " ")
        biased_sentence = biased_sentence.replace("\xa0", " ")
        words2remove_lang = words2remove.get(lang, [])
        template_words = [clean(x.strip()) for x in template.split(" ") if x.strip()]
        biased_sentence_words = [
            clean(x.strip()) for x in biased_sentence.split(" ") if x.strip()
        ]
        for w in words2remove_lang:
            template_words = [x for x in template_words if x != w]
            biased_sentence_words = [x for x in biased_sentence_words if x != w]
        placeholders, words_aligned = align_template_with_sentence(
            template_words, biased_sentence_words
        )
        if len(placeholders) != len(words_aligned) or len(placeholders) == 0:
            not_aligned.append((index, template_source, biased_sentence_source))
        else:
            for p, w in zip(placeholders, words_aligned):
                w_str = " ".join([x.lower() for x in w])
                if p not in alignement_by_placeholder.keys():
                    alignement_by_placeholder[p] = set()
                alignement_by_placeholder[p].add(w_str)
                if w_str not in alignement_by_word.keys():
                    alignement_by_word[w_str] = set()
                alignement_by_word[w_str].add(p)

"""Template/sentence pairs that failed to aligh"""

not_aligned

"""Phrases to replace aligned by more than one placeholder"""

sorted(
    {k: v for k, v in alignement_by_word.items() if len(v) > 1}\
    .items(), key=lambda item: -len(item[1]))

"""Phrases replaced by placeholders"""

dict(sorted(alignement_by_placeholder.items()))

"""## Check template differences between languages"""

import re
cols_to_check = [x for x in df_target_tab.columns if ': Templates' in x]
upper_case_not_placeholders = ["AIDS", "SIDA", "LKW", "RPA"]


for index, row in df_target_tab.iterrows():
    if type(row['English: Templates']) == str:
        english_comparison = re.findall('[A-Z-_:]{3,}', row['English: Templates'])

        diff = {}

        for col in cols_to_check:
            if type(row[col]) == str:
                m = re.findall('[A-Z-_:]{3,}', row[col])
                cleaned_slots = [x for x in m if x not in upper_case_not_placeholders]

                errors = []
                for item in cleaned_slots:
                    if item not in english_comparison:
                        errors.append(item)
                if len(errors)> 0:
                    diff[col] = errors


        if len(diff) > 0:
            diff['English: Templates'] = english_comparison
            print('Template difference in :' + str(row['Index']) + ' with: ' + str(diff))